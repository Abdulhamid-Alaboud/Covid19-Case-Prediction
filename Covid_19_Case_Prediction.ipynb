{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGrw8laeANnE"
      },
      "source": [
        "**Step-1: Dataset Collection**\n",
        "\n",
        "Dataset link: https://www.kaggle.com/datasets/imdevskp/corona-virus-report\n",
        "\n",
        "**Reason for selection:**\n",
        "\n",
        "This dataset contains over 49,000 time-stamped records for multiple countries with confirmed, deaths, recovered, active cases and geo-coordinates (lat/long), which makes it suitable for a binary classification.\n",
        "\n",
        "These attributes make it suitable for a binary classification project that predicts whether a record represents an infected or non-infected case.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tbeA4cQ78RUR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS1IHlbCBc7c"
      },
      "source": [
        "**Step-2: Data Understanding & EDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uO_jgJdoCKLn"
      },
      "source": [
        "2.1- Unzip and Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7cAFztVBtW8"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "with zipfile.ZipFile('Covid19.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('Covid19_data')\n",
        "df = pd.read_csv('Covid19_data/covid_19_clean_complete.csv')\n",
        "\n",
        "display(df.head())\n",
        "\n",
        "print(\"Shape:\", df.shape)\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9fhz4vFEObu"
      },
      "source": [
        "2.2- Check Missing Values and Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_nBGxuUEPpb"
      },
      "outputs": [],
      "source": [
        "print(\"Missing Values per Column:\")\n",
        "print(df.isnull().sum())\n",
        "print(\"Number of Duplicate Rows:\", df.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe-1-KJDEVBM"
      },
      "source": [
        "2.3- Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eR87NcLuEYQP"
      },
      "outputs": [],
      "source": [
        "print(\"Numeric Columns Statistics:\")\n",
        "display(df.describe())\n",
        "print(\"Categorical Columns Statistics:\")\n",
        "display(df.describe(include=['object']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO95b_kaEgk4"
      },
      "source": [
        "2.4- Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJOjm9f1Eh6I"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(style=\"whitegrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyHitgyMEkAW"
      },
      "source": [
        "2.4.1 – Monthly Trend of COVID-19 Cases (Confirmed, Recovered, and Deaths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DiwwQWClE1iw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "df['Month'] = pd.to_datetime(df['Date']).dt.month\n",
        "month_names = {\n",
        "    1:'Jan', 2:'Feb', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun',\n",
        "    7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'\n",
        "}\n",
        "df['Month_Name'] = df['Month'].map(month_names)\n",
        "monthly_data = df.groupby('Month_Name')[['Confirmed', 'Recovered', 'Deaths']].sum().reindex(\n",
        "    ['Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec']\n",
        ")\n",
        "plt.figure(figsize=(12,6))\n",
        "sns.lineplot(data=monthly_data, linewidth=2.5, markers=True)\n",
        "plt.title('Monthly Trend of COVID-19 Cases (Confirmed, Recovered, Deaths)')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Count')\n",
        "plt.grid(True, linestyle='--', alpha=0.6)\n",
        "plt.legend(['Confirmed', 'Recovered', 'Deaths'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCX3kTXJFCEN"
      },
      "source": [
        "2.4.2- Correlation Heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K21H-ryMFGLQ"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
        "corr = df[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(corr, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title('Correlation Heatmap Between Numerical Features', fontsize=14, pad=15)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4.3 – Visualizing Relationship with Active Cases"
      ],
      "metadata": {
        "id": "J8CU-JlVfJzd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confirmed vs Active"
      ],
      "metadata": {
        "id": "2F_yr1lsfPoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "sns.scatterplot(\n",
        "    x='Confirmed',\n",
        "    y='Active',\n",
        "    hue='WHO Region',\n",
        "    data=df,\n",
        "    alpha=0.6\n",
        ")\n",
        "plt.title(\"Active vs Confirmed Cases by WHO Region\")\n",
        "plt.xlabel(\"Confirmed Cases\")\n",
        "plt.ylabel(\"Active Cases\")\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tRpZ87ysfGHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recovered vs Active"
      ],
      "metadata": {
        "id": "s_WQWP00fSZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.lmplot(\n",
        "    x='Deaths',\n",
        "    y='Active',\n",
        "    data=df,\n",
        "    hue='WHO Region',\n",
        "    height=4,\n",
        "    aspect=1.3,\n",
        "    scatter_kws={'alpha':0.5}\n",
        ")\n",
        "plt.title(\"Active vs Deaths with Trend by Region\")\n",
        "plt.xlabel(\"Deaths\")\n",
        "plt.ylabel(\"Active Cases\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ahL-tb5Yfdvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.4.4- Geographical Spread (Infections & Deaths)"
      ],
      "metadata": {
        "id": "Y3HZH0r_g64-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "df_country = df.groupby('Country/Region', as_index=False)['Confirmed'].max()\n",
        "\n",
        "fig = px.choropleth(\n",
        "    df_country,\n",
        "    locations=\"Country/Region\",\n",
        "    locationmode=\"country names\",\n",
        "    color=\"Confirmed\",\n",
        "    color_continuous_scale=\"Reds\",\n",
        "    title=\"Global Map of COVID-19 Confirmed Cases (by country)\"\n",
        ")\n",
        "fig.show()\n"
      ],
      "metadata": {
        "id": "mSuBs5FOg7wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Step 2.4.5 – Composite Pandemic Impact Score (CPIS)\n"
      ],
      "metadata": {
        "id": "UcnXMOK6uCYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# aggregate data by WHO Region\n",
        "region_df = (\n",
        "    df.groupby('WHO Region')[['Confirmed', 'Deaths', 'Recovered']]\n",
        "      .sum()\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "# compute components\n",
        "region_df['Severity'] = region_df['Deaths'] / (region_df['Confirmed'] + 1)\n",
        "region_df['Recovery_Weakness'] = 1 - (region_df['Recovered'] / (region_df['Confirmed'] + 1))\n",
        "region_df['Spread'] = region_df['Confirmed']\n",
        "\n",
        "# normalize components to 0–1\n",
        "for col in ['Severity', 'Recovery_Weakness', 'Spread']:\n",
        "    mn = region_df[col].min()\n",
        "    mx = region_df[col].max()\n",
        "    region_df[col + '_norm'] = (region_df[col] - mn) / (mx - mn + 1e-9)\n",
        "\n",
        "# final composite score\n",
        "region_df['CPIS'] = (\n",
        "    region_df['Severity_norm'] * 0.4 +\n",
        "    region_df['Recovery_Weakness_norm'] * 0.3 +\n",
        "    region_df['Spread_norm'] * 0.3\n",
        ")\n",
        "\n",
        "# sort and plot\n",
        "region_df = region_df.sort_values('CPIS', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(x='CPIS', y='WHO Region', data=region_df, palette='magma')\n",
        "plt.title('Composite Pandemic Impact Score (CPIS) by WHO Region', fontsize=14, pad=15)\n",
        "plt.xlabel('CPIS (0–1)')\n",
        "plt.ylabel('WHO Region')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ew6Gh-hatxuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDfWOeN_ImyM"
      },
      "source": [
        "**Step-3: Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHtDXDpmJMxh"
      },
      "source": [
        "3.1- Handle Missing Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwutE4jsIwIZ"
      },
      "outputs": [],
      "source": [
        "print(\"Missing values per column:\")\n",
        "print(df.isnull().sum())\n",
        "df.fillna(0, inplace=True)\n",
        "print(\"After filling missing values:\")\n",
        "print(df.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YcHCnjjbJZqc"
      },
      "source": [
        "3.2- Encode Target Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-cldkXqJhu1"
      },
      "outputs": [],
      "source": [
        "df['Infected'] = df['Active'].apply(lambda x: 'Not Infected' if x == 0 else 'Infected')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "df['Infected_encoded'] = le.fit_transform(df['Infected'])\n",
        "print(df[['Infected', 'Infected_encoded']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AURkSbvsJoOk"
      },
      "source": [
        "3.3- Select Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LCjQdqvMJrUO"
      },
      "outputs": [],
      "source": [
        "features = ['Confirmed', 'Deaths', 'Recovered', 'Lat', 'Long']\n",
        "X = df[features]\n",
        "y = df['Infected_encoded']\n",
        "print(\"Features shape:\", X.shape)\n",
        "print(\"Target shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2wtXS3UJv49"
      },
      "source": [
        "3.4- Scale the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnFYMiM6J1El"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(\"Scaled features sample:\\n\", X_scaled[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPm7LTzIJ5_J"
      },
      "source": [
        "3.5- Split the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2FL1TuWLJ7dA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.3, random_state=42\n",
        ")\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aFgD92ecK26n"
      },
      "source": [
        "3.6- Percentage of Missing Values Handled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q13RrSdlK5a7"
      },
      "outputs": [],
      "source": [
        "# Missing values before filling\n",
        "missing_before = df.isnull().sum()\n",
        "total_rows = len(df)\n",
        "missing_after = df.isnull().sum()\n",
        "\n",
        "# Calculate percentage of processed missing values\n",
        "processed_percentage = (missing_before - missing_after) / total_rows * 100\n",
        "print(\"Percentage of missing values handled per column:\")\n",
        "print(processed_percentage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Dcu7ZaLh_L"
      },
      "source": [
        "**Step-4: Build the Model (Logistic Regression – Binary Classification)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o1GnfcVgMSB1"
      },
      "source": [
        "4.1- Import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmBykNktMP_Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e18ouEogMg08"
      },
      "source": [
        "4.2- Handle Imbalanced Data using SMOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Option 1: SMOOT"
      ],
      "metadata": {
        "id": "pZDZrezvZCho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ow9qmAF7MnU0"
      },
      "outputs": [],
      "source": [
        "smote = SMOTE(random_state=42)\n",
        "X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)\n",
        "print(\"SMOTE ->\", X_train_sm.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "“Option 2: Under Sampling”"
      ],
      "metadata": {
        "id": "RtcQ2ODQWBIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_under, y_train_under = rus.fit_resample(X_train, y_train)\n",
        "print(\"Under-sampling ->\", X_train_under.shape)"
      ],
      "metadata": {
        "id": "wuDRIkKfWnRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2.1- Compare SMOTE vs Under-Sampling performance for Logistic Regression\n"
      ],
      "metadata": {
        "id": "LbPDb3qD9DFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "log_sm = LogisticRegression(random_state=42)\n",
        "log_sm.fit(X_train_sm, y_train_sm)\n",
        "y_pred_sm = log_sm.predict(X_test)\n",
        "\n",
        "log_under = LogisticRegression(random_state=42)\n",
        "log_under.fit(X_train_under, y_train_under)\n",
        "y_pred_under = log_under.predict(X_test)\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred):\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(f\"\\n{name}\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1-score:  {f1:.4f}\")\n",
        "\n",
        "evaluate_model(\"Logistic Regression (SMOTE)\", y_test, y_pred_sm)\n",
        "evaluate_model(\"Logistic Regression (Under-Sampling)\", y_test, y_pred_under)\n"
      ],
      "metadata": {
        "id": "oNipVOYr9FvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysUkXLPNMsic"
      },
      "source": [
        "4.3- Initialize and Train the Model\n",
        "\n",
        "Option 1: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6i_zy0MNMwBn"
      },
      "outputs": [],
      "source": [
        "rus = RandomUnderSampler(random_state=42)\n",
        "X_train_res, y_train_res = rus.fit_resample(X_train, y_train)\n",
        "X_train_final = X_train_under\n",
        "y_train_final = y_train_under"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression(random_state=42)\n",
        "logreg.fit(X_train_final, y_train_final)"
      ],
      "metadata": {
        "id": "f8Rlf7IgZWyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1QdZzIZRFow"
      },
      "source": [
        "Option 2 (Recommended): Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "szwX3uslRHGe"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
        "rf.fit(X_train_final, y_train_final)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4- **BONUS: Two-Stage Classification Pipeline**"
      ],
      "metadata": {
        "id": "M5GOsV2n2u_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stage 1: fast / simple model\n",
        "stage1_pred = logreg.predict(X_test)\n",
        "\n",
        "# find samples that were misclassified by logistic regression\n",
        "mis_idx = stage1_pred != y_test\n",
        "\n",
        "# stage 2: re-predict only the hard samples using Random Forest\n",
        "stage2_pred = rf.predict(X_test[mis_idx])\n",
        "\n",
        "# combine\n",
        "final_pred = stage1_pred.copy()\n",
        "final_pred[mis_idx] = stage2_pred\n",
        "\n",
        "# evaluate final predictions\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "print(\"Two-Stage Pipeline Results:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, final_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, final_pred):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, final_pred):.4f}\")\n",
        "print(f\"F1-score: {f1_score(y_test, final_pred):.4f}\")\n"
      ],
      "metadata": {
        "id": "tSMjj6Qz2z__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.4.1- **Confusion Matrix – Two-Stage Pipeline**"
      ],
      "metadata": {
        "id": "LhbTV0fo3Cys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm_bonus = confusion_matrix(y_test, final_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_bonus,\n",
        "                              display_labels=['Not Infected', 'Infected'])\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.title(\"Confusion Matrix – Two-Stage Pipeline\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "i088XOxw2_Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAmyOxlsMze4"
      },
      "source": [
        "4.5- Make Predictions on Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31wAT17SM25W"
      },
      "outputs": [],
      "source": [
        "y_pred_logreg = logreg.predict(X_test)\n",
        "y_pred_rf = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSd_0LgzM51M"
      },
      "source": [
        "4.6- Compare Predictions with Actual Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9wPIm1eM8xP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "comparison_logreg = pd.DataFrame({\n",
        "    'Actual': y_test[:10].values,\n",
        "    'Predicted_LogReg': y_pred_logreg[:10]\n",
        "})\n",
        "comparison_rf = pd.DataFrame({\n",
        "    'Actual': y_test[:10].values,\n",
        "    'Predicted_RF': y_pred_rf[:10]\n",
        "})\n",
        "\n",
        "print(\"Logistic Regression Predictions:\\n\", comparison_logreg)\n",
        "print(\"Random Forest Predictions:\\n\", comparison_rf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ9lYxwMNzh-"
      },
      "source": [
        "**Step-5: Model Evaluation (Classification)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfhvMt-kN55U"
      },
      "source": [
        "5.1- Import Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "607OGtLvOCtU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zQfZolaOGpP"
      },
      "source": [
        "5.2- Calculate and Compare Metrics (Logistic Regression vs Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qf1iwyo1OKUV"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "acc_log = accuracy_score(y_test, y_pred_logreg)\n",
        "prec_log = precision_score(y_test, y_pred_logreg)\n",
        "rec_log = recall_score(y_test, y_pred_logreg)\n",
        "f1_log = f1_score(y_test, y_pred_logreg)\n",
        "\n",
        "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
        "prec_rf = precision_score(y_test, y_pred_rf)\n",
        "rec_rf = recall_score(y_test, y_pred_rf)\n",
        "f1_rf = f1_score(y_test, y_pred_rf)\n",
        "\n",
        "print(\"=== Model Evaluation Metrics ===\")\n",
        "print(f\"{'Metric':<12}{'Logistic Regression':<25}{'Random Forest'}\")\n",
        "print(f\"{'-'*50}\")\n",
        "print(f\"{'Accuracy':<12}{acc_log:<25.4f}{acc_rf:.4f}\")\n",
        "print(f\"{'Precision':<12}{prec_log:<25.4f}{prec_rf:.4f}\")\n",
        "print(f\"{'Recall':<12}{rec_log:<25.4f}{rec_rf:.4f}\")\n",
        "print(f\"{'F1-score':<12}{f1_log:<25.4f}{f1_rf:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XyWLIzsOMfy"
      },
      "source": [
        "5.3- Confusion Matrix Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlIEC4bkOQq7"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "cm_log = confusion_matrix(y_test, y_pred_logreg)\n",
        "cm_rf  = confusion_matrix(y_test, y_pred_rf)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "disp1 = ConfusionMatrixDisplay(confusion_matrix=cm_log,\n",
        "                               display_labels=['Not Infected', 'Infected'])\n",
        "disp1.plot(ax=axes[0], cmap=plt.cm.Oranges, colorbar=False)\n",
        "axes[0].set_title(\"Logistic Regression Confusion Matrix\")\n",
        "\n",
        "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm_rf,\n",
        "                               display_labels=['Not Infected', 'Infected'])\n",
        "disp2.plot(ax=axes[1], cmap=plt.cm.Blues, colorbar=False)\n",
        "axes[1].set_title(\"Random Forest Confusion Matrix\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6kOwbIeOSpA"
      },
      "source": [
        "5.4- ROC Curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg-v-tS5OW0c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_prob_log = logreg.predict_proba(X_test)[:, 1]\n",
        "y_prob_rf  = rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n",
        "fpr_log, tpr_log, _ = roc_curve(y_test, y_prob_log)\n",
        "fpr_rf,  tpr_rf,  _ = roc_curve(y_test, y_prob_rf)\n",
        "\n",
        "auc_log = auc(fpr_log, tpr_log)\n",
        "auc_rf  = auc(fpr_rf, tpr_rf)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr_log, tpr_log, label=f\"Logistic Regression (AUC = {auc_log:.2f})\")\n",
        "plt.plot(fpr_rf,  tpr_rf,  label=f\"Random Forest (AUC = {auc_rf:.2f})\")\n",
        "\n",
        "plt.plot([0,1], [0,1], 'k--')\n",
        "\n",
        "plt.title(\"ROC Curves for Different Models\")\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}